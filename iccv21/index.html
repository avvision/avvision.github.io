<!doctype html>
<html>
<head>
    <meta charset="utf-8">

    <title>Homepage</title>
    <link rel="icon" href="favicon.png" type="image/png">

    <link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,300,800italic,700italic,600italic,400italic,300italic,800,700,600' rel='stylesheet' type='text/css'>

    <link href="css/bootstrap.css" rel="stylesheet" type="text/css">
    <link href="css/style.css" rel="stylesheet" type="text/css">
    <link href="css/font-awesome.css" rel="stylesheet" type="text/css">
    <link href="css/animate.css" rel="stylesheet" type="text/css">


    <!--
    <meta name="viewport" content="width=device-width, maximum-scale=1">
    -->

    <!-- <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/> -->

    <!-- <link href="css/responsive.css" rel="stylesheet" type="text/css"> -->

    <!-- [if IE]><style type="text/css">.pie {behavior:url(PIE.htc);}</style><![endif] -->

    <script type="text/javascript" src="js/jquery.1.8.3.min.js"></script>
    <script type="text/javascript" src="js/bootstrap.js"></script>
    <script type="text/javascript" src="js/jquery-scrolltofixed.js"></script>
    <script type="text/javascript" src="js/jquery.easing.1.3.js"></script>
    <script type="text/javascript" src="js/jquery.isotope.js"></script>
    <script type="text/javascript" src="js/wow.js"></script>
    <script type="text/javascript" src="js/classie.js"></script>
    <script src="contactform/contactform.js"></script>


    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-173267821-2"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-173267821-2');
    </script>

    <meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no" />
</head>

<style>
    /*自定义的H1 H2类型*/
    h1.Program {
        color: black;
        font-size: 27px;
        text-align: left;
    }
    h2.Program {
        color: black;
        font-size: 20px;
        text-align: left;
    }
</style>

<style>
    /*body{transform: scale(1);}*/

    span {
    color: #888888;
    font-family: 'Open Sans', sans-serif;
    font-size: 1em; /*原来是16px*/
    font-weight:450;
    }


    div.container {
    font-size: 1.6rem;
    text-align: justify;
    /* text-justify: inter-word; */
    }  

    div.nav {
    text-align: center;
    /* text-justify: inter-word; */
    }  

    div.pc {
    text-align: center;
    /* position: relative; */
    /* margin-bottom: -5rem; */
    /* text-justify: inter-word; */
    }  

</style>




<body>
<header class="header" id="header"> <!--header-start-->
        
        <div>
        <figure class="logo animated fadeInDown delay-07s">
            <a href="https://avvision.xyz/"><img src="img/logo.png" class="left"></a>
        </figure>
        <br>

        <h1 class="animated fadeInDown delay-07s" >2nd AVVision Workshop</h1>
        <ul class="we-create animated fadeInUp delay-1s">
            <br>
            <li>ICCV 2021 -- 10/17/2021</li>
        </ul>
        </div>

</header><!--header-end-->


<nav class="main-nav-outer" id="test"> <!--main-nav-start-->
    <div class="nav">
        <ul class="main-nav"> <!--可以改bar的字体大小-->
            <li><a href="#about" >About</a></li>
            <li><a href="#speakers" >Speakers</a></li>
            <li><a href="#organizers" >Organizers</a></li>
            <li><a href="#submission" >Submission</a></li>
            <li><a href="#Program">Program</a></li>
            <li><a href="#sponsor">Sponsors</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
    </div>
</nav>


<section class="main-section paddind" id="about">
    <div class="container">
        <h2>About</h2>
        <!-- <h6></h6> 这里一行太多了-->
        <!-- <P class="padding-b"> -->
        The 2nd Autonomous Vehicle Vision (AVVision) Workshop 
        <!-- is organized
        by the <a href="https://avvision.xyz/">AVVision community</a>. This workshop  -->
        aims
        to bring together industry professionals and academics to
        brainstorm and exchange ideas on the advancement of computer vision techniques
        for autonomous driving.
        In this one-day workshop,
        we will have seven keynote talks and
        regular paper presentations (oral and poster)
        to discuss the state of the art as well as existing challenges in autonomous driving.
        <!-- </P> -->
    </div>
</section>



<section class="main-section paddind" id="speakers">
    <div class="container " >
        <h2>Speakers</h2>
        <!-- <h6></h6> 这里一行太多了-->

        <div class="portfolioContainer_new wow fadeInUp delay-02s text-align:center" >

            <div class="Portfolio-box printdesign" >
                <a href="https://thoth.inrialpes.fr/~schmid/"><img src="img/cordelia.png" alt=""></a>
                <h3>Cordelia Schmid</h3>
                <p>INRIA</p>
            </div>

            <div class="Portfolio-box webdesign">
                <a href="http://www.cs.toronto.edu/~urtasun/"><img src="img/raquel.png" alt=""></a>
                <h3>Raquel Urtasun</h3>
                <p>University of Toronto</p>
            </div>

            <div class="Portfolio-box branding">
                <a href="http://www.cvlibs.net/"><img src="img/andreas.png" alt=""></a>
                <h3>Andreas Geiger</h3>
                <p>University of Tübingen</p>
            </div>

            <div class="Portfolio-box photography" >
                <a href="https://www.yf.io/"><img src="img/fisher.png" alt=""></a>
                <h3>Fisher Yu</h3>
                <p>ETH Zürich</p>
            </div>
        </div>
    </div>


    <div class="container" style="margin-top: 1rem">
        <div class="portfolioContainer_new wow fadeInUp delay-02s" id="my_speakers">

            <div class="Portfolio-box branding">
                <a href="https://dvl.in.tum.de/team/lealtaixe/"><img src="img/laura.png" alt=""></a>
                <h3>Laura Leal-Taixé</h3>
                <p>Technical University of Munich</p>
            </div>


            <div class="Portfolio-box photography">
                <a href="https://droplab.engin.umich.edu/matthew-johnson-roberson"><img src="img/matthew.png" alt=""></a>
                <h3>Matthew Johnson-Roberson</h3>
                <p>University of Michigan</p>
            </div>

            <div class="Portfolio-box photography" >
                <a href="http://carlwellington.com/"><img src="img/carl.png" alt=""></a>
                <h3>Carl Wellington</h3>
                <p>Aurora</p>
            </div>


        </div>

    </div>
</section>


<section class="main-section paddind" id="organizers">
    <div class="container">
        <h2>Organizers</h2>
        <h6>General Chairs</h6>

        <div class="portfolioContainer_new wow fadeInUp delay-02s text-align:center" >

            <div class="Portfolio-box printdesign" >
                <a href="https://www.ruirangerfan.com/"><img src="img/rui_fan.png" alt=""></a>
                <h3>Rui Ranger Fan</h3>
                <p>Tongji University</p>
            </div>

            <div class="Portfolio-box webdesign">
                <a href="https://djurikom.github.io/"><img src="img/nemanja.png" alt=""></a>
                <h3>Nemanja Djuric</h3>
                <p>Aurora</p>
            </div>

            <div class="Portfolio-box branding">
                <a href="https://rowanmcallister.github.io/"><img src="img/rowan512.png" alt=""></a>
                <h3>Rowan McAllister</h3>
                <p>Toyota Research Institute</p>
            </div>

            <div class="Portfolio-box photography" >
                <a href="http://poseidon.csd.auth.gr/LAB_PEOPLE/IPitas.htm"><img src="img/ioannis_pitas.png" alt=""></a>
                <h3>Ioannis Pitas</h3>
                <p>Aristotle University of Thessaloniki</p>
            </div>
        </div>
    </div>


        <br>
        <div class="pc">
            <h6>Program Committee</h6>
                
                <div class="pc-member">
                    <h4 style="float: left">
                    David J. Kriegman
                    <span>
                    UC San Diego
                    </span>
                    Qijun Chen 
                    <span>
                    Tongji University
                    </span>
                    Walterio Mayol-Cuevas
                    <span>
                    Uni. of Bristol & Amazon
                    </span>
                    Xinchen Yan 
                    <span>
                    Uber ATG
                    </span>
                    Xiang Gao
                    <span>
                    Idriverplus
                    </span>  
                    Ming Liu
                    <span>
                    HKUST
                    </span> 
                    Jianping He
                    <span>
                    SJTU  
                    </span> 
                    Junhao Xiao
                    <span>
                    NUDT
                    </span>  
                    Kai Han
                    <span>
                    Uni. of Bristol
                    </span>  
                    Hesham Eraqi
                    <span>
                    American University in Cairo
                    </span> 
                    Wenshuo Wang
                    <span>
                    McGill University
                    </span> 
                    Yue Wang
                    <span>
                    Zhejiang University
                    </span>
                    Nachuan Ma
                    <span>
                    Tongji University
                    </span>
                    Jiahe Fan
                    <span>
                    Beijing Institute of Technology
                    </span>
                    </h4>





                </div>

                <div class="pc-member">
                    <h4 style="float: left">
                        Joshua Manela
                        <span>
                        Waymo
                        </span>
                        Dequan Wang
                        <span>
                        UC Berkeley
                        </span>
                        Sen Jia 
                        <span>
                        Uni. of Waterloo
                        </span>
                        Yi Zhou
                        <span>
                        HKUST
                        </span>
                        Mohammud J. Bocus 
                        <span>
                        Uni. Of Bristol
                        </span>
                        Lei Qiao
                        <span>
                        SJTU
                        </span>  
                        Peng Yun
                        <span>
                        HKUST
                        </span>
                        Meng Fan
                        <span>
                        Aurora
                        </span>  
                        Hengli Wang
                        <span>
                        HKUST
                        </span>
                        Yuan Wang
                        <span>
                        SmartMore 
                        </span>  
                        Henggang Cui 
                        <span>
                        Motional
                        </span>  
                        Zhuwen Li
                        <span>
                        Nuro Inc. 
                        </span>
                        Yun Peng
                        <span>
                        Tongji University 
                        </span>
                        Meet Shah
                        <span>
                        Waymo
                        </span>
                    </h4>



                </div>

                <div class="pc-member">


                    <h4 style="float: left">
                        Shangxuan
                        <span>
                        Waymo
                        </span>
                        Lingyao Zhang
                        <span>
                        Aurora  
                        </span>
                        Carl Wellington
                        <span>
                        Aurora
                        </span>
                        Huaiyang Huang
                        <span>
                        HKUST
                        </span>
                        Shivam Gautam
                        <span>
                        Aurora  
                        </span>
                        Weikai Chen
                        <span>
                        Tencent America
                        </span> 
                        Peide Cai
                        <span>
                        HKUST
                        </span>
                        Bohuan Xue
                        <span>
                        HKUST
                        </span>  
                        Slobodan Vucetic 
                        <span>
                        Temple University
                        </span>  
                        Zhaoen Su
                        <span>
                        Aurora
                        </span>  
                        Fang-Chieh Chou
                        <span>
                        Aurora
                        </span>
                        Shuai Su
                        <span>
                        Tongji University
                        </span>
                        Jiayuan Du
                        <span>
                        Tongji University
                        </span>    
                        Nick Rhinehard
                        <span>
                        UC Berkeley
                        </span>
                    </h4>


                </div>

        </div>



    </div>
</section>



<section class="main-section paddind" id="submission">
    <div class="container">
        <h2>Submission</h2>
        <h6 style="margin-bottom: 15px">Call for papers</h6>
        With a number of breakthroughs in autonomous system technology
        over the past decade, the race to commercialize self-driving
        cars has become fiercer than ever.
        The integration of advanced sensing, computer vision,
        signal/image processing, and machine/deep learning into autonomous
        vehicles enables them to perceive the environment
        intelligently and navigate safely. Autonomous driving is
        required to ensure safe, reliable, and efficient automated
        mobility in complex uncontrolled real-world environments.
        Various applications range from automated transportation
        and farming to public safety and environment exploration.
        Visual perception is a critical component of autonomous driving.
        Enabling technologies include:
        a) affordable sensors that can acquire useful data under
        varying environmental conditions, b) reliable simultaneous
        localization and mapping, c) machine learning that can
        effectively handle varying real-world conditions and unforeseen
        events, as well as “machine-learning friendly” signal processing
        to enable more effective classification and decision making,
        d) hardware and software co-design for efficient real-time
        performance, e) resilient and robust platforms that can withstand
        adversarial attacks and failures, and f) end-to-end system
        integration of sensing, computer vision, signal/image
        processing and machine/deep learning. The 2nd AVVision
        workshop will cover all these topics. Research papers are
        solicited in, but not limited to, the following topics:
        <br>
        <br>
        <ul>

            <li> 3D road/environment reconstruction and understanding; </li>
            <li> Mapping and localization for autonomous cars; </li>
            <li> Semantic/instance driving scene segmentation and semantic mapping; </li>
            <li> Self-supervised/unsupervised visual environment perception; </li>
            <li> Car/pedestrian/object/obstacle detection/tracking and 3D localization; </li>
            <li> Car/license plate/road sign detection and recognition; </li>
            <li> Driver status monitoring and human-car interfaces; </li>
            <li> Deep/machine learning and image analysis for car perception; </li>
            <li> Adversarial domain adaptation for autonomous driving; </li>
            <li> On-board embedded visual perception systems; </li>
            <li> Bio-inspired vision sensing for car perception; </li>
            <li> Real-time deep learning inference. </li>
        </ul>

        <h6 style="margin-bottom: 15px; margin-top: 20px" >Important Dates</h6>
        <ul>
            <li> Submission deadline: Jul. 25, 2021 </li>
            <li> Review feedback release date: Aug. 11, 2021 </li>
            <li> Camera-ready Submission: Aug. 16, 2021 </li>
        </ul>




        <h6 style="margin-bottom: 15px; margin-top: 20px" > Submission Guidelines</h6>
        <b>Regular papers</b>: Authors are encouraged to submit high-quality, original
        (i.e., not been previously published or accepted for publication
        in substantially similar form in any peer-reviewed venue 
        including journal, conference or workshop) research.

        The paper template is identical to the <a href="http://iccv2021.thecvf.com/node/4#submission-guidelines">ICCV 2021</a> main conference.
        Papers are limited to eight pages, including figures and tables, 
        in the ICCV style. Additional pages containing only cited 
        references are allowed. Please refer to the following files for 
        detailed formatting instructions:

        <br>
        <br>
        <ul>
        <li>Example submission paper with detailed instructions <a href="http://iccv2021.thecvf.com/sites/default/files/2020-09/egpaper_for_review.pdf">Download</a>; </li>
        <li>LaTeX Templates (zip): iccv2021AuthorKit.zip <a href="http://iccv2021.thecvf.com/sites/default/files/2020-09/iccv2021AuthorKit.zip">Download</a></li>
        </ul>
    
        Papers that are not properly anonymized, or do not use the template, or have more than eight pages (excluding references) will be rejected without review. 
        The <a href="https://easychair.org/conferences/?conf=avvision2021">submission site</a> is now open. 

        <br>
        <br>
        <b>Extended abstracts:</b> We encourage participants to submit preliminary ideas that have not been published before as 
        extended abstracts. These submissions would benefit from additional exposure and discussion that can shape a better 
        future publication. We also invite papers that have been published at other venues to spark discussions and foster new collaborations. 
        Submissions may consist of up to four pages plus one additional page solely for references (using the template detailed above). The extended abstracts will <b>NOT</b> be published in the workshop proceedings.


        <h6 style="margin-bottom: 15px; margin-top: 20px" > Accepted Papers</h6>
        <ol>
            <li> <b>Monocular 3D Localization of Vehicles in Road Scenes </b> <br>
                Haotian Zhang, Haorui Ji, Aotian Zheng, Jenq-Neng Hwang, Ren-Hung Hwang <br>
                <a href=papers/1/CameraReady/01.pdf>paper</a>

            </li>
            <li> <b>DriPE: A Dataset for Human Pose Estimation in Real-World Driving Settings</b> <br>
                Romain Guesdon, Carlos Crispim-Junior, Laure Tougne <br>
                <a href=papers/2/CameraReady/02.pdf>paper</a>
            </li>


            <li><b>On the Road to Large-Scale 3D Monocular Scene Reconstruction using Deep Implicit Functions</b> <br>
                Thomas Roddick, Benjamin Biggs, Daniel Olmeda Reino, Roberto Cipolla <br>
                <a href=papers/3/CameraReady/22.pdf>paper</a> |
                <a href=papers/3/CameraReady/22-supmat.pdf>supplementary material</a>

            </li>
            <li><b>Weakly Supervised Approach for Joint Object and Lane Marking Detection</b> <br>
                Pranjay Shyam, Kuk-Jin Yoon, Kyung-Soo Kim <br>
                <a href=papers/4/CameraReady/04.pdf>paper</a>
            </li>



            </li>
            <li><b>Speak2Label: Using Domain Knowledge for Creating a Large Scale Driver GazeZone Estimation Dataset</b> <br>
                Shreya Ghosh, Abhinav Dhall, Garima Sharma, Sarthak Gupta, Nicu Sebe <br>
                <a href=papers/5/CameraReady/05.pdf>paper</a> |
                <a href=papers/5/CameraReady/05-supp.pdf>supplementary material</a>
            </li>


            </li>
            <li><b>Multi-weather city: Adverse weather stacking for autonomous driving</b> <br>
                Valentina Musat, Ivan Fursa, Paul Newman, Fabio Cuzzolin, Andrew Bradley <br>
                <a href=papers/6/CameraReady/06.pdf>paper</a>
            </li>


            </li>
            <li><b>YOLinO: Generic Single Shot Polyline Detection in Real Time</b> <br>
                Annika Meyer,
                Jan-Hendrik Pauls,
                Christoph Stiller <br>
                <a href=papers/7/CameraReady/07.pdf>paper</a> |
                <a href=papers/7/CameraReady/07-supp.pdf>supplementary material</a>
            </li>

            </li>
            <li><b>Frustum-PointPillars: A Multi-Stage Approach for 3D Object Detection
                using RGB Camera and LiDAR</b> <br>
                Anshul Paigwar,
                David Sierra-Gonzalez,
                Özgür Erkent,
                Christian Laugier<br>
                <a href=papers/8/CameraReady/08.pdf>paper</a>
            </li>

            </li>
            <li><b>Occupancy Grid Mapping with Cognitive Plausibility
                for Autonomous Driving Applications</b> <br>
                Alice Plebe,
                Julian F. P. Kooij,
                Gastone Pietro Rosati Papini,
                Mauro Da Lio<br>
                <a href=papers/9/CameraReady/09.pdf>paper</a>
            </li>

            </li>
            <li><b>A Computer Vision-Based Attention Generator using DQN</b> <br>
                Jordan Chipka,
                Shuqing Zeng,
                Thanura Elvitigala,
                Priyantha Mudalige<br>
                <a href=papers/10/CameraReady/10.pdf>paper</a>
            </li>

            </li>
            <li><b>RaidaR: A Rich Annotated Image Dataset of Rainy Street Scenes</b> <br>
                Jiongchao Jin,
                Arezou Fatemi,
                Wallace Michel Pinto Lira,
                Fenggen Yu,
                Biao Leng,
                Rui Ma,
                Ali Mahdavi-Amiri,
                Hao Zhang<br>
                <a href=papers/11/CameraReady/11.pdf>paper</a> |
                <a href=papers/11/CameraReady/11-supp.pdf>supplementary material</a>
            </li>
<!--
            </li>
            <li><b>where is paper 12?</b>
            </li>
-->
            </li>
            <li><b>CDAda: A Curriculum Domain Adaptation for Nighttime Semantic
                Segmentation</b> <br>
                Qi Xu,
                Yinan Ma, Jing Wu, Chengnian Long,
                Xiaoling Huang

                <br>
                <a href=papers/13/CameraReady/13.pdf>paper</a>
            </li>
<!--
            </li>
            <li><b>where is paper 14?</b>
            </li>
-->
            </li>
            <li><b>Causal BERT: Improving object detection
                by searching for challenging groups</b> <br>
                Cinjon Resnick,
                Or Litany,
                Amlan Kar,
                Karsten Kreis,
                James Lucas,
                Kyunghyun Cho,
                Sanja Fidler<br>
                <a href=papers/15/CameraReady/31.pdf>paper</a> |
                <a href=papers/15/CameraReady/31-supp.pdf>supplementary material</a>
            </li>

            </li>
            <li><b>CenterPoly: real-time instance segmentation using bounding polygons</b> <br>
                Hughes Perreault, Guillaume-Alexandre Bilodeau, Nicolas Saunier, Maguelonne Héritier
              <br>
                <a href=papers/16/CameraReady/16.pdf>paper</a>
            </li>


            <li><b>It’s All Around You: Range-Guided Cylindrical Network
                for 3D Object Detection</b> <br>
                Meytal Rapoport-Lavie, Dan Raviv
                <br>
                <a href=papers/17/CameraReady/17.pdf>paper</a>
            </li>

            </li>
            <li><b>SCARF: A Semantic Constrained Attention Refinement Network
                for Semantic Segmentation</b> <br>
                Xiaofeng Ding,
                Chaomin Shen,
                Zhengping Che,
                Tieyong Zeng,
                Yaxin Peng<br>
                <a href=papers/18/CameraReady/18.pdf>paper</a> |
                <a href=papers/18/CameraReady/18-supp.pdf>supplementary material</a>
            </li>

            <li><b>SDVTracker: Real-Time Multi-Sensor Association and Tracking for Self-Driving</b> <br>
                Shivam Gautam,
                Gregory P. Meyer,
                Carlos Vallespi-Gonzalez,
                Brian C. Becker
                <br>
                <a href=papers/19/CameraReady/19.pdf>paper</a>
            </li>

            <li><b>SA-Det3D: Self-Attention Based Context-Aware 3D Object Detection</b> <br>
                Prarthana Bhattacharyya,
                Chengjie Huang,
                Krzysztof Czarnecki
                <br>
                <a href=papers/20/CameraReady/20.pdf>paper</a>
            </li>

            <li><b>Semantics-aware Multi-modal Domain Translation:
                From LiDAR Point Clouds to Panoramic Color Images</b> <br>
                Tiago Cortinhal,
                Fatih Kurnaz,
                Eren Erdal Aksoy
                <br>
                <a href=papers/21/CameraReady/2021155282.pdf>paper</a>
            </li>

            <li><b>SS-SFDA : Self-Supervised Source-Free Domain Adaptation for Road
                Segmentation in Hazardous Environments</b> <br>
                Divya Kothandaraman, Rohan Chandra, Dinesh Manocha
                <br>
                <a href=papers/22/CameraReady/22.pdf>paper</a>
            </li>

            <li><b>Graph Convolutional Networks for 3D Object Detection on Radar Data</b> <br>
                Michael Meyer,
                Georg Kuschk,
                Sven Tomforde
                <br>
                <a href=papers/23/CameraReady/23.pdf>paper</a>
            </li>

            <li><b>Few-Shot Batch Incremental Road Object Detection via Detector Fusion</b> <br>
                Anuj Tambwekar,
                Kshitij Agrawal,
                Anay Majee,
                Anbumani Subramanian
                <br>
                <a href=papers/24/CameraReady/24.pdf>paper</a>
            </li>

            <li><b>Synthetic Data Generation using Imitation Training</b> <br>
                Aman Kishore,
                Tae Eun Choe,
                Junghyun Kwon,
                Minwoo Park,
                Pengfei Hao,
                Akshita Mittel
                <br>
                <a href=papers/25/CameraReady/25.pdf>paper</a>
            </li>

            <li><b>Efficient Uncertainty Estimation in Semantic Segmentation via Distillation</b> <br>
                Christopher J. Holder, Muhammad Shafique
                <br>
                <a href=papers/26/CameraReady/26.pdf>paper</a>
            </li>
   <!--         no 27 -->
            <li><b>Visual Reasoning using Graph Convolutional Networks for
                Predicting Pedestrian Crossing Intention</b> <br>
                Tina Chen,
                Renran Tian,
                Zhengming Ding
                <br>
                <a href=papers/28/CameraReady/28.pdf>paper</a>
            </li>

            <li><b>Cross-modal Matching CNN for Autonomous Driving Sensor Data Monitoring</b> <br>
                Yiqiang Chen,
                Feng Liu, Ke Pei
                <br>
                <a href=papers/29/CameraReady/29.pdf>paper</a>
            </li>
            <!--         no 31 -->
            <li><b>Multi-Stage Fusion for Multi-Class 3D Lidar Detection</b> <br>
                Zejie Wang,
                Zhen Zhao,
                Zhao Jin,
                Zhengping Che,
                Jian Tang,
                Chaomin Shen,
                Yaxin Peng
                <br>
                <a href=papers/31/CameraReady/31.pdf>paper</a>
            </li>

        </ol>



    </div>

</section>


<section class="main-section paddind" id="Program">
    <div class="container ">
        <h2>Program</h2>

        <h1>
        <b>Opening Remark</b>: 07:00--07:05
        </h1>
        <h1>
        <b>Keynote Session I</b>: 07:05--08:25
        </h1>
        <!-- <h8></h8> -->
        07:05--07:45 Andreas Geiger<br>
        07:45--08:25 Fisher Yu<br>
        <h1>
        <b>Oral Paper Session I</b>: 08:25--09:25 <br>
        </h1>
        <!-- <li> -->
        08:25--08:35
        <a href=https://www.youtube.com/watch?v=uXUQ7LfuAog&list=PL51IczHEeqwSdk2U7Bx9ev-bmkdkzjOtf&index=4&t=5s>CDAda: A Curriculum Domain Adaptation for Nighttime Semantic Segmentation</a>, Qi Xu et al.<br>
        08:35--08:45 
        <a href=https://www.youtube.com/watch?v=lQa0OF6a1IU&list=PL51IczHEeqwSdk2U7Bx9ev-bmkdkzjOtf&index=5>SCARF: A Semantic Constrained Attention Refinement Network for Semantic Segmentation</a>, Xiaofeng Ding et al. <br>
        08:45--08:55 
        <a href=https://www.youtube.com/watch?v=Gm8G1cCGxSk&list=PL51IczHEeqwSdk2U7Bx9ev-bmkdkzjOtf&index=1>Few-Shot Batch Incremental Road Object Detection via Detector Fusion</a>, Anuj Tambwekar et al. <br>
        08:55--09:05 
        <a href=https://www.youtube.com/watch?v=zC8TU0EG__4&list=PL51IczHEeqwSdk2U7Bx9ev-bmkdkzjOtf&index=11>SA-Det3D: Self-Attention Based Context-Aware 3D Object Detection</a>, Prarthana Bhattacharyya et al. <br>
        09:05--09:15
        <a href=https://www.youtube.com/watch?v=0z7OPPRsqTk&list=PL51IczHEeqwSdk2U7Bx9ev-bmkdkzjOtf&index=9>Frustum-PointPillars: A Multi-Stage Approach for 3D Object Detection Using RGB Camera and LiDAR</a>, Anshul Paigwar et al. <br>
        09:15--09:25
        <a href=https://www.youtube.com/watch?v=ciucxkAvRGM&list=PL51IczHEeqwSdk2U7Bx9ev-bmkdkzjOtf&index=6>DriPE: A Dataset for Human Pose Estimation in Real-World Driving Settings</a>, Romain Guesdon et al. <br>

        <h1>
        <b>Keynote Session II</b>: 09:25--10:45
        </h1>
        09:25--10:05 Raquel Urtasun<br>
        10:05--10:45 Matthew Johnson-Roberson<br>
        <h1>

            
        <h1>
        <b>Poster Paper Session</b>: 10:45--13:25
        </h1>

        <h1>
        <b>Lunch Break</b>:  13:25--13:55 
        </h1>

        <h1>
        <b>Keynote Session III</b>: 13:55--15:55 
        </h1>
        13:55--14:35 Laura Leal-Taixé <br>
        14:35--15:15 Cordelia Schmid  <br>
        15:15--15:55 Carl Wellington <br>

        <h1><b>Oral Paper Session II</b>: 15:55--16:55 <br>
        </h1>
        <!-- <li> -->
        08:25--08:35
        <a href=https://www.youtube.com/watch?v=7V6A8jZ-QVY&t=37s>Graph Convolutional Networks for 3D Object Detection on Radar Data</a>, Michael Meyer et al.<br>
        08:35--08:45 
        <a href=https://www.youtube.com/watch?v=jOKLa773adM&list=PL51IczHEeqwSdk2U7Bx9ev-bmkdkzjOtf&index=2>CenterPoly: Real-Time Instance Segmentation Using Bounding Polygons</a>, Hughes Perreault et al. <br>
        08:45--08:55 
        <a href=https://www.youtube.com/watch?v=vf5NTqU3894&list=PL51IczHEeqwSdk2U7Bx9ev-bmkdkzjOtf&index=8>RaidaR: A Rich Annotated Image Dataset of Rainy Street Scenes</a>, Jiongchao Jin et al. <br>
        08:55--09:05 
        <a href=https://www.youtube.com/watch?v=rA2lVT7mhhA&list=PL51IczHEeqwSdk2U7Bx9ev-bmkdkzjOtf&index=12>SDVTracker: Real-Time Multi-Sensor Association and Tracking for Self-Driving Vehicles</a>, Shivam Gautam et al. <br>
        09:05--09:15
        <a href=https://www.youtube.com/watch?v=8GDh-0q_UaA&list=PL51IczHEeqwSdk2U7Bx9ev-bmkdkzjOtf&index=10>Self-Supervised Source-Free Domain Adaptation for Road Segmentation in Hazardous Environments</a>, Divya Kothandaraman et al. <br>
        09:15--09:25
        <a href=https://www.youtube.com/watch?v=SY5HGWoViH4&list=PL51IczHEeqwSdk2U7Bx9ev-bmkdkzjOtf&index=7>Monocular 3D Localization of Vehicles in Road Scenes</a>, Haotian Zhang et al. <br>



        <h1>
        <b>Closing Remark</b>: 16:55--17:00 
        </h1>
        















        <!--  WACV的Program格式的字体放在这里特别丑
            <h2 class="Program">
                Keynote Talk -- Prof. Andreas Geiger	07:05 -- 07:35
            </h2>
    -->


    </div>
</section>



<section class="main-section paddind" id="sponsor">
    <div class="container " >
        <h2>Sponsors</h2>
<br>
        <div class="portfolioContainer_new wow fadeInUp delay-02s text-align:center" >

            <div class="Portfolio-box printdesign" >
                <a href=""><img src="img/nvidia-logo.png" alt=""></a>
            </div>


        </div>
    </div>

</section>

<div class="container" style="margin-top: 5rem">
    <h2>Contact</h2>
    <section class="main-section contact" id="contact">

        <div class="row" >
            <div class="col-lg-6 col-sm-7 wow fadeInLeft">


                <div class="contact-info-box phone clearfix">
                    <h3><i class="fa-phone"></i>Phone: +1 (412) 710-6868</h3>
                    
                </div>
                <div class="contact-info-box email clearfix">
                    <h3><i class="fa-envelope"></i>E-Mail: avvision@mias.group</h3>
                    
                </div>
                <ul class="social-link">
                    <li class="twitter"><a href="https://twitter.com/mias_avvision"><i class="fa-twitter"></i></a></li>
                    <li class="facebook"><a href="https://www.facebook.com/AVVision-102524081821979/"><i class="fa-facebook"></i></a></li>
                    <li class="pinterest"><a href="https://www.youtube.com/channel/UCL0Uxgn1f_3Dup31dtWe-QQ"><i class="fa-youtube"></i></a></li>
                    <li class="gplus"><a href="img/qr_code.jpg"><i class="fa-wechat"></i></a></li>
                </ul>
            </div>
            <div class="col-lg-6 col-sm-5 wow fadeInUp delay-05s">
                
                <div class="form">

                    <div id="sendmessage">Your message has been sent. Thank you!</div>
                    <div id="errormessage"></div>
                    <form action="mailto:avvision@mias.group" method="post" enctype="text/plain">
                        <div class="form-group">
                            <input type="text" name="Name: " class="form-control form-footer" placeholder="Name" required="Name">
                            <div class="validation"></div>
                        </div>
                        <div class="form-group">
                            <input type="text" name="Email: " class="form-control form-footer" placeholder="Email" required="Email">
                            <div class="validation"></div>
                        </div>
                        <div class="form-group">
                            <textarea type="text" name="Message: " class="form-control form-footer" rows="10" placeholder="Message" required="Message"></textarea>
                            <div class="validation"></div>
                        </div>

                        <div class="text-center"><button type="submit" class="input-btn">Send Message</button></div>
                    </form>
                </div>



            </div>
        </div>
    </section>
</div>


<!-- Messenger Chat plugin Code -->
<div id="fb-root"></div>

<!-- Your Chat plugin code -->
<div id="fb-customer-chat" class="fb-customerchat">
</div>

<script>
  var chatbox = document.getElementById('fb-customer-chat');
  chatbox.setAttribute("page_id", "102524081821979");
  chatbox.setAttribute("attribution", "biz_inbox");

  window.fbAsyncInit = function() {
    FB.init({
      xfbml            : true,
      version          : 'v11.0'
    });
  };

  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = 'https://connect.facebook.net/en_US/sdk/xfbml.customerchat.js';
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>

<footer class="footer">
    <div class="container">
        <div class="footer-logo"><a href="https://avvision.xyz/"><img src="img/logo.png" alt=""></a></div>
        <span class="copyright">&copy; 2021 AVVision. All Rights Reserved.</span>

    </div>
</footer>


<script type="text/javascript">
    $(document).ready(function(e) {
        $('#test').scrollToFixed();
        $('.res-nav_click').click(function(){
            $('.main-nav').slideToggle();
            return false

        });

    });
</script>

<script>
    wow = new WOW(
        {
            animateClass: 'animated',
            offset:       100
        }
    );
    wow.init();
</script>


<script type="text/javascript">
    $(window).load(function(){

        $('.main-nav li a, .servicelink').bind('click',function(event){
            var $anchor = $(this);

            $('html, body').stop().animate({
                scrollTop: $($anchor.attr('href')).offset().top - 102
            }, 1500,'easeInOutExpo');


            if ($(window).width() < 768 ) {
                $('.main-nav').hide();
            }
            event.preventDefault();
        });
    })
</script>


<script type="text/javascript">
    (function(){
        var designW = 1080;  //设计稿宽
        var font_rate = 10;
        //适配
        document.getElementsByTagName("html")[0].style.fontSize = document.body.offsetWidth / designW * font_rate + "px";
        document.getElementsByTagName("body")[0].style.fontSize = document.body.offsetWidth / designW * font_rate + "px";

        //监测窗口大小变化
        window.addEventListener("onorientationchange" in window ? "orientationchange" : "resize", function() {
            document.getElementsByTagName("html")[0].style.fontSize = document.body.offsetWidth / designW * font_rate + "px";
            document.getElementsByTagName("body")[0].style.fontSize = document.body.offsetWidth / designW * font_rate + "px";
        }, false);

    })();
</script>

<script type="text/javascript">

    $(window).load(function(){


        var $container = $('.portfolioContainer'),
            $body = $('body'),
            colW = 375,
            columns = null;

        var a ;
        var speakers;
        a= document.getElementById('my_speakers');
        speakers = a.getElementsByTagName('div').length;

        $container.isotope({
            // disable window resizing
            resizable: true,
            masonry: {
                columnWidth: colW
            }
        });

        $(window).smartresize(function(){
            // check if columns has changed
            var currentColumns = Math.floor( ( $body.width() -30 ) / colW );

            if ( currentColumns !== columns ) {
                // set new column count
                columns = currentColumns;
                // apply width to container manually, then trigger relayout
                $container.width( columns * colW )
                    .isotope('reLayout');
            }

        }).smartresize(); // trigger resize to set container width
        $('.portfolioFilter a').click(function(){
            $('.portfolioFilter .current').removeClass('current');
            $(this).addClass('current');

            var selector = $(this).attr('data-filter');
            $container.isotope({

                filter: selector,
            });
            return false;
        });

    });

</script>

</body>
</html>
